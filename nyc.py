# -*- coding: utf-8 -*-
"""NYC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IraUzui8YsXnCLb8-aVBIRb4vu99JuFS
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import dask.dataframe as dd

import folium #open street map
import datetime #Convert to unix time
import calendar

import time #Convert to unix time
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use('classic')
# %matplotlib inline
import pandas as pd
sns.set()
import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LinearRegression

from google.colab import drive 
drive.mount('/Data')

"""## 1.Create a sample submission

df = pd.read_csv("Data/test.csv");
new = df["key"]
new.shape
new = df[['key']].copy()
new["fare_amount"] = 11.35
new.to_csv("Data/Sample_submission.csv",index=False)
"""

dataDf = pd.read_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/train.csv",nrows=20000000)

dataDf.dtypes
#print(dataDf.shape)

dataDf.pickup_latitude = pd.to_numeric(dataDf.pickup_latitude,errors='coerce')
dataDf.pickup_longitude = pd.to_numeric(dataDf.pickup_longitude,errors='coerce')
dataDf.dropoff_latitude = pd.to_numeric(dataDf.dropoff_latitude,errors='coerce')
dataDf.dropoff_longitude = pd.to_numeric(dataDf.dropoff_longitude,errors='coerce')
dataDf.passenger_count = pd.to_numeric(dataDf.passenger_count,errors='coerce')
dataDf.fare_amount = pd.to_numeric(dataDf.fare_amount,errors='coerce')

dataDf.dtypes
print(dataDf.shape)

df = dataDf.copy()
df.dtypes

df.head()

"""## 2.Data Preprocessing

#### 1.Latitude and Longitude values
"""

outside_nyc = df[((df.pickup_longitude<= -74.15)|(df.pickup_latitude<=40.5774))|\
                  ((df.pickup_longitude >= -73.7004)|(df.pickup_latitude>=40.9176))|\
                  ((df.dropoff_longitude<= -74.15)|(df.dropoff_latitude<=40.5774))|\
                  ((df.dropoff_longitude >= -73.7004)|(df.dropoff_latitude>=40.9176))]

# pickup and dropoff locations that are outside NewYork are considere as outliers for our analysis

map_osm = folium.Map(location=[40.734695, -73.990372], tiles='Stamen Toner')
sample_locations = outside_nyc.head(1000)

for i,j in sample_locations.iterrows():
    if int(j['pickup_latitude']) != 0:
        if (((j.pickup_longitude<= -74.15)|(j.pickup_latitude<=40.5774))|\
                  ((j.pickup_longitude >= -73.7004)|(j.pickup_latitude>=40.9176))):
            folium.Marker(list((j['pickup_latitude'],j['pickup_longitude']))).add_to(map_osm)
        if (((j.dropoff_longitude<= -74.15)|(j.dropoff_latitude<=40.5774))|\
                  ((j.dropoff_longitude >= -73.7004)|(j.dropoff_latitude>=40.9176))):
            folium.Marker(list((j['dropoff_latitude'],j['dropoff_longitude']))).add_to(map_osm)
            
map_osm

def get_map(data):
    map_osm = folium.Map(location=[40.734695, -73.990372], tiles='Stamen Toner')
    sample_locations = data.head(1000)

    for i,j in sample_locations.iterrows():
        folium.Marker(list((j['pickup_latitude'],j['pickup_longitude']))).add_to(map_osm)
        folium.Marker(list((j['dropoff_latitude'],j['dropoff_longitude']))).add_to(map_osm)
            
    return map_osm

#drop rows with outliers in lattitude and longitude values

df_p1 = df[((df.pickup_longitude>= -74.15)&(df.pickup_latitude>=40.5774))&\
                  ((df.pickup_longitude <= -73.7004)&(df.pickup_latitude<=40.9176))&\
                  ((df.dropoff_longitude>= -74.15)&(df.dropoff_latitude>=40.5774))&\
                  ((df.dropoff_longitude <= -73.7004)&(df.dropoff_latitude<=40.9176))]

# pickup and dropoff locations after removing outliers

maps = get_map(df_p1)
maps

df_p1.head()

print(df_p1.isnull().sum())

df_p1.shape

"""#### 2.Trip Distance"""

# creating a new feature distance of travell using the latitude and longitude data
import geopy.distance

dist = []

for i in range(df_p1.shape[0]):
  cord_1 = (df_p1.pickup_latitude.values[i],df_p1.pickup_longitude.values[i])    
  cord_2 = (df_p1.dropoff_latitude.values[i],df_p1.dropoff_longitude.values[i])
  dist.append(geopy.distance.vincenty(cord_1,cord_2).miles)

df_p1["trip_distance"] = dist

df_p1.head()

df_p1 = df_p1[df_p1.trip_distance>0]

df_p1[df_p1.trip_distance==0].shape

"""#### 3.Pickup datetime"""

df_p1['pickup_datetime'] = pd.to_datetime(df_p1['pickup_datetime'] ,format='%Y-%m-%d %H:%M:%S UTC' )

df_p1['pickup_date']= df_p1['pickup_datetime'].dt.date
df_p1['pickup_day']=df_p1['pickup_datetime'].apply(lambda x:x.day)
df_p1['pickup_hour']=df_p1['pickup_datetime'].apply(lambda x:x.hour)
df_p1['pickup_day_of_week']=df_p1['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])
df_p1['pickup_month']=df_p1['pickup_datetime'].apply(lambda x:x.month)
df_p1['pickup_year']=df_p1['pickup_datetime'].apply(lambda x:x.year)

df_p1.head()

#encoding day of the week to numbers
def encodeDays(day_of_week):
    day_dict={'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6}
    return day_dict[day_of_week]

df_p1['pickup_day_of_week']=df_p1['pickup_day_of_week'].apply(lambda x:encodeDays(x))

df_p1.head()

#timeDf.head()
#timeDf.shape

print(df_p1.isnull().sum())
df_p1.shape

"""#### 4.Fare amount"""

#checking negative price values
df_p1.loc[df_p1['fare_amount']<0].shape

#Minimum fare amount is $2.5


df_p1=df_p1[(df_p1['fare_amount']>=2.5) & (df_p1['fare_amount']<=300)]
##df_p1.shape

df_p1.loc[df_p1['fare_amount']<0].shape

"""#### 5.Passenger Count"""

#checking negative passenger count
df_p1.loc[df_p1['passenger_count']<=0].shape

df_p1 = df_p1.loc[df_p1['passenger_count']>0]
df_p1[df_p1['passenger_count']<0].shape

df_p1.head()

"""#### 6.Weekends"""

# Sunday Saturday and Friday are considered as weekends. The coulm will have a value of 1 for pickup day of week 5,0,6
def isWeekend(data):
  conditions = [((data['pickup_day_of_week']==0) | (data['pickup_day_of_week']==5) | (data['pickup_day_of_week']==6))]
  choices  = [1];
  data["isWeekend"] = np.select(conditions,choices,default=0)
  return data

df_p1 = isWeekend(df_p1)

df_p1.head()

"""#### 7.Surge Hours"""

def isSurge(data):
  conditions = [((data['pickup_hour']>=3) & (data['pickup_hour']<=6))]
  choices  = [1];
  data["isSurge"] = np.select(conditions,choices,default=0)
  return data

"""### 8.Adding airport columns"""

JFK={'min_lng':-73.8895, 
                  'min_lat':40.7664, 
                  'max_lng':-73.8550, 
                  'max_lat':40.7931}
JFK_center=[40.6437,-73.7900]
# Get all pickups to JFK
JFK_data=df_p1.loc[(df_p1.pickup_latitude>=JFK['min_lat']) & (df_p1.pickup_latitude<=JFK['max_lat'])]
JFK_data=JFK_data.loc[(df_p1.pickup_longitude>=JFK['min_lng']) & (df_p1.pickup_longitude<=JFK['max_lng'])]

print("Number of Trips with Pickups from JFK",JFK_data.shape[0])

JFK_dropoff=df_p1.loc[(df_p1.dropoff_latitude>=JFK['min_lat']) & (df_p1.dropoff_latitude<=JFK['max_lat'])]
JFK_dropoff=JFK_dropoff.loc[(df_p1.dropoff_longitude>=JFK['min_lng']) & (df_p1.dropoff_longitude<=JFK['max_lng'])]

print("Number of Trips with Dropoffs to JFK",JFK_dropoff.shape[0])

plt.figure(figsize=(8,5))
sns.kdeplot(np.log(JFK_data['fare_amount'].values),label='JFK Pickups')
sns.kdeplot(np.log(JFK_dropoff['fare_amount'].values),label='JFK Dropoff')
sns.kdeplot(np.log(df_p1['fare_amount'].values),label='All Trips in Train data')
plt.title("Fare Amount Distribution")

nyc_airports={'JFK':{'min_lng':-73.8352,
     'min_lat':40.6195,
     'max_lng':-73.7401, 
     'max_lat':40.6659},
              
    'EWR':{'min_lng':-74.1925,
            'min_lat':40.6700, 
            'max_lng':-74.1531, 
            'max_lat':40.7081

        },
    'LaGuardia':{'min_lng':-73.8895, 
                  'min_lat':40.7664, 
                  'max_lng':-73.8550, 
                  'max_lat':40.7931
        
    }
    
}



def isAirport(latitude,longitude,airport_name='JFK'):
    
    if latitude>=nyc_airports[airport_name]['min_lat'] and latitude<=nyc_airports[airport_name]['max_lat'] and longitude>=nyc_airports[airport_name]['min_lng'] and longitude<=nyc_airports[airport_name]['max_lng']:
        return 1
    else:
        return 0

df_p1['is_pickup_JFK']=df_p1.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)
df_p1['is_dropoff_JFK']=df_p1.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)

df_p1['is_pickup_EWR']=df_p1.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)
df_p1['is_dropoff_EWR']=df_p1.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)

df_p1['is_pickup_la_guardia']=df_p1.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'LaGuardia'),axis=1)
df_p1['is_dropoff_la_guardia']=df_p1.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'LaGuardia'),axis=1)

df_p1.head()

df_p1.to_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/train_proc.csv",index=False)



"""### 9.Store Preprocessed data"""

df_p1.to_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/train_proc.csv",index=False)

df_p1 = pd.read_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/train_proc.csv")

df_p1.head()

"""## 3.Exploratory Data Analysis

#### 1.PDF
"""

#sns.distplot(df_p1['pickup_year']);
#plt.axvline(0, color="k", linestyle="--");
sns.FacetGrid(df_p1,size=10) \
   .map(sns.distplot, "fare_amount") \
   .add_legend();
plt.show();

sns.FacetGrid(df_p1,size=10) \
   .map(sns.distplot, "pickup_hour") \
   .add_legend();
plt.show();

sns.FacetGrid(df_p1,size=10) \
   .map(sns.distplot, "pickup_day_of_week") \
   .add_legend();
plt.show();

sns.FacetGrid(df_p1,size=10) \
   .map(sns.distplot, "passenger_count") \
   .add_legend();
plt.show();

"""#### 2.Scatter plots"""

sns.scatterplot(x='trip_distance',y='fare_amount',data=df_p1)

#df_p1.loc[df_p1['fare_amount']>300].shape

#df_p1=df_p1[(df_p1['fare_amount']<500)]

#sns.scatterplot(x='trip_distance',y='fare_amount',data=df_p1)

sns.scatterplot(x='pickup_hour',y='fare_amount',data=df_p1)

df_p1=df_p1[(df_p1['passenger_count']<10)]

sns.scatterplot(x='passenger_count',y='fare_amount',data=df_p1)

"""### 3.Bar Graphs"""

pickup_year_avg_fares =df_p1.groupby(['pickup_year'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='pickup_year',y='avg_fare_amount',data=pickup_year_avg_fares).set_title("Avg Fare Amount over Years")

avg_fares =df_p1.groupby(['pickup_hour'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='pickup_hour',y='avg_fare_amount',data=avg_fares).set_title("Avg Fare Amount over Hours")

avg_fares =df_p1.groupby(['pickup_hour'])['key'].count().reset_index().rename(columns={'key':'Num_of_trips'})
sns.barplot(x='pickup_hour',y='Num_of_trips',data=avg_fares).set_title("Number of trips over Hours")

avg_fares =df_p1.groupby(['pickup_day_of_week'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='pickup_day_of_week',y='avg_fare_amount',data=avg_fares).set_title("Avg Fare Amount over Day of week")

avg_fares =df_p1.groupby(['pickup_day_of_week'])['key'].count().reset_index().rename(columns={'key':'Num_of_trips'})
sns.barplot(x='pickup_day_of_week',y='Num_of_trips',data=avg_fares).set_title("Number of trips over day_of_week")

avg_fares =df_p1.groupby(['pickup_month'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='pickup_month',y='avg_fare_amount',data=avg_fares).set_title("Avg Fare Amount over Months")

avg_fares =df_p1.groupby(['pickup_month'])['key'].count().reset_index().rename(columns={'key':'Num_of_trips'})
sns.barplot(x='pickup_month',y='Num_of_trips',data=avg_fares).set_title("Number of trips over pickup_month")

avg_fares =df_p1.groupby(['passenger_count'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='passenger_count',y='avg_fare_amount',data=avg_fares).set_title("Avg Fare Amount over passenger count")

avg_fares =df_p1.groupby(['pickup_day'])['fare_amount'].mean().reset_index().rename(columns={'fare_amount':'avg_fare_amount'})
sns.barplot(x='pickup_day',y='avg_fare_amount',data=avg_fares).set_title("Avg Fare Amount over pickup day")

df_p1.columns
df_p1.shape

"""## 4.Process test data"""

testDf = pd.read_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/test.csv")

testDf.head()

testDf.shape

# split datetime into year month and week

testDf['pickup_datetime'] = pd.to_datetime(testDf['pickup_datetime'] ,format='%Y-%m-%d %H:%M:%S UTC' )

testDf['pickup_date']= testDf['pickup_datetime'].dt.date
testDf['pickup_day']=testDf['pickup_datetime'].apply(lambda x:x.day)
testDf['pickup_hour']=testDf['pickup_datetime'].apply(lambda x:x.hour)
testDf['pickup_day_of_week']=testDf['pickup_datetime'].apply(lambda x:calendar.day_name[x.weekday()])
testDf['pickup_month']=testDf['pickup_datetime'].apply(lambda x:x.month)
testDf['pickup_year']=testDf['pickup_datetime'].apply(lambda x:x.year)
testDf['pickup_day_of_week']=testDf['pickup_day_of_week'].apply(lambda x:encodeDays(x))


testDf.head()

testDf['is_pickup_JFK']=testDf.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)
testDf['is_dropoff_JFK']=testDf.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)

testDf['is_pickup_EWR']=testDf.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)
testDf['is_dropoff_EWR']=testDf.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)

testDf.head()

# create a trip distance column for test data

dist = []

for i in range(testDf.shape[0]):
  cord_1 = (testDf.pickup_latitude.values[i],testDf.pickup_longitude.values[i])    
  cord_2 = (testDf.dropoff_latitude.values[i],testDf.dropoff_longitude.values[i])
  try:
    dist.append(geopy.distance.vincenty(cord_1,cord_2).miles)
  except ValueError:
    dist.append(0)
 
testDf["trip_distance"] = dist

testDf['trip_distance'][testDf.trip_distance!=0].count()

testDf.to_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/test_proc.csv",index=False)

"""## 5.Model Building"""

#load preprocessed train and test data

df_p1 = pd.read_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/train_proc.csv")
testDf = pd.read_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/test_proc.csv")

testDf['is_pickup_JFK']=testDf.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'JFK'),axis=1)
testDf['is_dropoff_JFK']=testDf.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'JFK'),axis=1)

testDf['is_pickup_EWR']=testDf.apply(lambda row:isAirport(row['pickup_latitude'],row['pickup_longitude'],'EWR'),axis=1)
testDf['is_dropoff_EWR']=testDf.apply(lambda row:isAirport(row['dropoff_latitude'],row['dropoff_longitude'],'EWR'),axis=1)

testDf.dropoff_latitude.fillna(0, inplace=True)
testDf.dropoff_longitude.fillna(0, inplace=True)
testDf.isnull().sum()

testDf.to_csv("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/test_proc.csv",index=False)
testDf.head()

#features = ["trip_distance","pickup_longitude","pickup_latitude","dropoff_longitude","dropoff_latitude","pickup_year","pickup_hour","passenger_count","is_pickup_JFK","is_dropoff_JFK","is_pickup_EWR","is_dropoff_EWR"]
features = ["trip_distance","pickup_longitude","pickup_latitude","dropoff_longitude","dropoff_latitude","pickup_year","pickup_hour","pickup_month","passenger_count","pickup_day_of_week","is_pickup_JFK","is_dropoff_JFK","is_pickup_EWR","is_dropoff_EWR"]
#features = ["trip_distance","pickup_longitude","pickup_latitude","dropoff_longitude","dropoff_latitude","pickup_year","pickup_hour","pickup_month","passenger_count","pickup_day_of_week"]
trainDf_final = df_p1.loc[:,features]
fareDf_train = df_p1.loc[:,["fare_amount"]]
fareDf_train.head()

print(trainDf_final.shape)
print(fareDf_train.shape)

trainDf_final.columns

testDf_final = testDf.loc[:,features]
testDf_final.columns

print(testDf_final.shape)
testDf_final.head()

trainDf_final  = trainDf_final.loc[:15000000,:]
fareDf_train =  fareDf_train.loc[:15000000:,:]

#function to create dataframe in submission format from predicted values of fares

def createSubmission(testDf,pred_values):
  submission = pd.DataFrame(
      {'key': testDf.key, 'fare_amount': pred_values[:]},
      columns = ['key', 'fare_amount'])
  return submission

testDf_final.dropna()
trainDf_final.dropna()
fareDf_train.dropna()

# Feature Scaling
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
trainDf_final_scaled = sc.fit_transform(trainDf_final)
testDf_final_scaled = sc.transform(testDf_final)

type(trainDf_final_scaled)
testDf_final.mean()

trainDf_final = trainDf_final.reset_index()
testDf_final = testDf_final.reset_index()
fareDf_train = fareDf_train.reset_index()

from sklearn.ensemble import RandomForestRegressor

regressor = RandomForestRegressor(n_estimators=300, random_state=0)
regressor.fit(trainDf_final, fareDf_train)
fare_predDf = regressor.predict(testDf_final)

##run this

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(trainDf_final,fareDf_train)
fare_pred = rf.predict(testDf_final)

submission  = createSubmission(testDf,fare_pred)

submission.to_csv('/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/submission_rforest_new.csv', index = False)
print("Dimension of submission :",submission.shape)
submission.head()

"""### 1.XGboost"""

#testDf_final['trip_distance'][testDf_final.trip_distance==0].count()
testDf_final.shape

import xgboost as xgb

xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.8, learning_rate = 0.15,
                max_depth = 3, alpha = 10, n_estimators = 100)

xg_reg.fit(trainDf_final,fareDf_train)
fare_pred = xg_reg.predict(testDf_final)

##new xgboost
import xgboost as xgb
xg_reg = xgb.XGBRegressor(n_estimator=201,max_depth=17,random_state=0)

xg_reg.fit(trainDf_final,fareDf_train)
fare_pred = xg_reg.predict(testDf_final)

submission  = createSubmission(testDf,fare_pred)

submission.to_csv('/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/submission_xgboost_new.csv', index = False)
print("Dimension of submission :",submission.shape)
submission.head()

fare_pred.shape

trainDf_final.head()

import xgboost as xgb

matrix_train = xgb. DMatrix(trainDf_final,fareDf_train);
model=xgb.train(params=params,
                    dtrain=matrix_train,num_boost_round=5000)
fare_pred = model.predict(xgb.DMatrix(testDf_final), ntree_limit = model.best_ntree_limit)



"""### 2.LightGBM"""

import lightgbm as lgb
lgb_train = lgb.Dataset(trainDf_final, label=fareDf_train)
params = {
    'boosting_type': 'rf',
    'objective': 'regression',
    'metric': {'l2', 'l1'},
    'learning_rate': 0.1,
    'num_iterations' : 300,
    'feature_fraction': 0.9,
    #'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': 0
}
gbm = lgb.train(params,
                lgb_train,
                num_boost_round=20)

fare_pred = gbm.predict(testDf_final, num_iteration=gbm.best_iteration)

gbm.save_model("/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/model_lgbm.txt")

trainDf_final.head()
fareDf_train.head()
testDf_final.head()
print(trainDf_final.shape)
print(fareDf_train.shape)
print(testDf_final.shape)

import lightgbm as lgb

train_data=lgb.Dataset(trainDf_final,label=fareDf_train)
param = {'num_leaves':31, 'num_trees':5000,'objective':'regression'}
param['metric'] = 'l2_root'
num_round=2000
cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)
lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))
fare_pred = lgb_bst.predict(testDf_final)

submission  = createSubmission(testDf,fare_pred)

submission.to_csv('/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/Data/submission_23.csv', index = False)
print("Dimension of submission :",submission.shape)
submission.head()

from sklearn.externals import joblib 
  
# Save the model as a pickle in a file 
joblib.dump(lgb_bst, '/Data/My Drive/ML/NYC_Taxi_Fare_Prediction/model_lgbm_new.pkl')

"""## 6.Conclusion and Results

Root mean square value of 5.13099 was obtained on the Kaggle test data
"""

